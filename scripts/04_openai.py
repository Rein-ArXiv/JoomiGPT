# scripts/02_summarize_chunks_openai.py

import os
import time
from glob import glob
from pathlib import Path

from openai import OpenAI
from tqdm import tqdm

BASE_DIR    = Path(__file__).resolve().parent.parent
CHUNKS_DIR  = BASE_DIR / "data" / "chunks"        # ì›ë³¸ ì²­í¬(txt)
SUMMARY_DIR = BASE_DIR / "data" / "summaries"     # ìš”ì•½ë³¸ ì €ì¥
SUMMARY_DIR.mkdir(exist_ok=True, parents=True)

client = OpenAI()           # OPENAI_API_KEY from env
MODEL  = "gpt-4o"
BATCH  = 5                  # í•œ ë²ˆì— ì²˜ë¦¬í•  ì¤„(ìŠ¤í¬ë¦½íŠ¸) ê°œìˆ˜
TEMP   = 0.0                # ê²°ì •ì  ìš”ì•½

SYSTEM_PROMPT = (
    "ë‹¹ì‹ ì€ ì‹ìŒë£Œ ì¹¼ëŸ¼ë‹ˆìŠ¤íŠ¸ì…ë‹ˆë‹¤.\n"
    "ì•„ë˜ ìœ íŠœë¸Œ ì˜ìƒ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì½ê³ , ìŒì‹Â·ìˆ  í˜ì–´ë§ í•µì‹¬ë§Œ ë‹´ì•„ 2~3ë¬¸ì¥ì˜ ë§¤ë„ëŸ¬ìš´ í•œêµ­ì–´ë¡œ ìš”ì•½í•˜ì„¸ìš”.\n"
    "ë¶ˆí•„ìš”í•œ ëŒ€í™”ì²´ëŠ” ì œê±°í•˜ê³ , ë°˜ë“œì‹œ ìŒì‹ëª…ê³¼ ìˆ  í˜ì–´ë§ ì •ë³´ë¥¼ í¬í•¨í•´ ì£¼ì„¸ìš”.\n"
    "ì¶œë ¥ì€ ì…ë ¥ ìˆœì„œëŒ€ë¡œ, í•œ ì¤„ì— í•˜ë‚˜ì˜ ìš”ì•½ì„ ë°˜í™˜í•©ë‹ˆë‹¤."
)

def batcher(lines, n):
    for i in range(0, len(lines), n):
        yield lines[i : i + n]

def summarize_batch(lines_batch: list[str]) -> list[str]:
    prompt = "\n\n---\n\n".join(lines_batch)
    resp = client.chat.completions.create(
        model=MODEL,
        temperature=TEMP,
        messages=[
            {"role": "system",  "content": SYSTEM_PROMPT},
            {"role": "user",    "content": prompt},
        ],
    )
    # ëª¨ë¸ì´ êµ¬ë¶„ìë¡œ ì‘ë‹µí–ˆë‹¤ê³  ê°€ì •í•˜ê³  split
    outputs = resp.choices[0].message.content.strip().split("\n\n---\n\n")
    # ë§Œì•½ ê¸¸ì´ê°€ ë‹¤ë¥´ë©´, ë‚¨ëŠ” ë¶€ë¶„ì€ ë¹ˆë¬¸ì¥ìœ¼ë¡œ ì±„ìš°ê±°ë‚˜ ì›ë³¸ì„ ëŒë ¤ì¤Œ
    if len(outputs) < len(lines_batch):
        # simple fallback: pad with originals (or "")
        outputs += [""] * (len(lines_batch) - len(outputs))
    return outputs[: len(lines_batch)]

def process_file(fp: Path):
    lines = fp.read_text(encoding="utf-8").splitlines()
    summaries = []

    for batch in tqdm(list(batcher(lines, BATCH)), desc=fp.name):
        summaries.extend(summarize_batch(batch))
        time.sleep(0.2)  # rate-limit ì™„í™”

    outp = SUMMARY_DIR / fp.name
    outp.write_text("\n".join(summaries), encoding="utf-8")
    print(f"âœ… {fp.name} â†’ {outp} ({len(summaries)} summaries)")

if __name__ == "__main__":
    files = list(CHUNKS_DIR.glob("*.txt"))
    print(f"Found {len(files)} chunk files.")
    for f in files:
        process_file(f)
    print("ğŸ‰ All summaries generated.")

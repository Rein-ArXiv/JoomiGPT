import requests
from pprint import pprint
import time

headers = {"Content-Type": "application/json"}
BASE_URL = "https://api.arxivxplorer.com"

# ğŸ” ê²€ìƒ‰í•  ì¿¼ë¦¬ ë¦¬ìŠ¤íŠ¸
queries = [
    "food science",
    "molecular gastronomy",
    "chemical analysis of food",
    "wine and cheese pairing",
    "cocktail chemistry",
    "flavor molecule graph neural networks",
    "umami prediction models",
    "LLM for recipe generation"
]

def search_arxiv(query, count=3):
    """arXiv Xplorerì—ì„œ ì˜ë¯¸ë¡ ì  ë…¼ë¬¸ ê²€ìƒ‰"""
    url = f"{BASE_URL}/search"
    payload = {
        "query": query,
        "method": "semantic",
        "count": count,
        "page": 1
    }
    res = requests.post(url, json=payload, headers=headers)
    return res.json()

def get_sections(paper_id):
    """ë…¼ë¬¸ì˜ ìœ íš¨ ì„¹ì…˜ì„ ì „ë¶€ ì¶œë ¥"""
    print(f"\n\n======================")
    print(f"ğŸ“˜ ë…¼ë¬¸ ID: {paper_id}")
    
    # ë©”íƒ€ë°ì´í„° ì¡°íšŒ
    meta_url = f"{BASE_URL}/read_paper_metadata"
    meta_payload = {"paper_id": paper_id, "show_abstract": True}
    meta_res = requests.post(meta_url, json=meta_payload, headers=headers)
    meta_json = meta_res.json()

    print(f"ğŸ“„ Title: {meta_json.get('title')}")
    print(f"ğŸ‘¨â€ğŸ”¬ Authors: {meta_json.get('authors')}")
    print(f"ğŸ“… Date: {meta_json.get('date')}")
    print(f"ğŸ“‘ Abstract: {meta_json.get('abstract')[:300]}...\n")

    toc_raw = meta_json.get("table_of_contents", "")
    section_titles = [line.strip() for line in toc_raw.strip().split("\n") if line.strip()]
    print(f"ğŸ“š Found {len(section_titles)} sections (TOC ê¸°ì¤€)")

    for section_id in range(1, len(section_titles) + 1):
        print(f"\nğŸ” Section {section_id}: {section_titles[section_id - 1]}")

        section_url = f"{BASE_URL}/read_section"
        section_payload = {"paper_id": paper_id, "section_id": section_id}
        section_res = requests.post(section_url, json=section_payload, headers=headers)

        try:
            content = section_res.json()
            if "Error" in content and "list index out of range" in content["Error"]:
                print("âŒ ìœ íš¨í•˜ì§€ ì•Šì€ ì„¹ì…˜ì…ë‹ˆë‹¤. ë£¨í”„ ì¢…ë£Œ.")
                break
        except Exception:
            content = section_res.text

        print("ğŸ“– ë‚´ìš©:\n")
        pprint(content)  # ì¼ë¶€ë§Œ ë³´ê¸° ì¢‹ê²Œ ì¶œë ¥
        print("\n" + "-"*50)
        time.sleep(0.5)  # ê³¼ë„í•œ ìš”ì²­ ë°©ì§€ìš©

# ğŸ” ì „ì²´ ì¿¼ë¦¬ ìˆœíšŒ
for query in queries:
    print(f"\n\nğŸ§  QUERY: {query}")
    papers = search_arxiv(query)

    for paper in papers:
        print(f"\nâ–¶ï¸ ë…¼ë¬¸: {paper['title']} ({paper['date']})")
        print(f"   â†³ ID: {paper['id']}")
        print(f"   â†³ First Author: {paper['first_author']}")
        print(f"   â†³ Abstract Snippet: {paper['abstract_snippet']}...\n")

        # ì‹¤ì œ ì„¹ì…˜ ë‚´ìš©ê¹Œì§€ ì¶œë ¥
        get_sections(paper["id"])

        time.sleep(2)  # API Rate limit ëŒ€ì‘
